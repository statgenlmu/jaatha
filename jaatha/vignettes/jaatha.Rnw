% \VignetteIndexEntry{The Jaatha HowTo}
% \VignetteDepends{jaatha}
% \VignettePackage{jaatha}

\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}

\usepackage{natbib}
\usepackage{graphics}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{hyperref}

<<foo,include=FALSE,echo=FALSE>>=
options(keep.source = TRUE, width = 60)
jinfo <- packageDescription("jaatha")
load('startpoints.save')
@

\hypersetup{
	pdftitle={The Jaatha HowTo \Sexpr{jinfo$Version}},
	pdfauthor={\Sexpr{jinfo$Author}},
	colorlinks=true,
	linkcolor=black,          % color of internal links
	citecolor=black,        % color of links to bibliography
	filecolor=black,      % color of file links
	urlcolor=blue           % color of external links
}

\begin{document}


\title{The Jaatha HowTo}
\author{\Sexpr{jinfo$Author}}
\date{Version \Sexpr{jinfo$Version}}
\maketitle

\section{Introduction}
\noindent
Jaatha is a fast composite likelihood method to estimate model parameters of the 
demographic history of (at the moment) two related species. To do so, it uses SNP
data from multiple individuals from both species.
This HowTo describes the method and gives an example of using its implementation
as an \verb@R@ package \verb@jaatha@.

A detailed description of Jaatha can be found in 
\cite{naduvilezhath_jaatha:_2011}, which also is the correct citation for Jaatha. 
Further explanations of all functions used can be found in the R help pages of Jaatha
as well as in the Jaatha manual. The package itself can be obtained from CRAN
using \verb@install.packages('jaatha')@ or downloaded from
\url{http://evol.bio.lmu.de/_statgen/software/jaatha}.

\section{A demographic model}
\noindent
Before we can apply Jaatha to estimate parameter, we first need to create a model
of the demographic history of the species. 
For now, assume that we know that our two species are closely related; hence they must 
have separated at a certain time in the past. There may be still gene flow between them, 
which we will refer to as migration from one population into the other. 
Hence, we could propose the simple demographic model described in Figure~\ref{fig:dm}.

\begin{figure}
\begin{center}
\includegraphics[width=60mm]{dm.png}
\end{center}
\caption{
A simple demographic model: The ancestral population splits into two populations $\tau$ time 
units ago, and afterwards individuals migrated from one population to the other with a 
migration rate $M$. Mutations are occurring with rate $\theta$ and recombination with a 
known rate $\rho$.}
\label{fig:dm}
\end{figure}

To specify the model in \verb@R@, we first need to load \verb@jaatha@.
<<Loading Jaatha>>=
library(jaatha)
@
We can now create an 'empty' demographic model \verb@dm@ using the \verb@dm.createDemographicModel()@
function:
<<Creating a demographic model in R>>=
dm <- dm.createDemographicModel(sample.sizes=c(25,24), loci.num=100,
						seq.length=10^3)
@
The parameter \verb@sampleSizes@ here corresponds to the number of individuals we have
sampled from the first population and second population respectively. The 
second argument \verb@nLoci@ states that we are using data from $100$ independent loci
while \verb@seqLength@ gives the (average) length of each loci\footnote{This 
is only used when a finite sites model is assumed or if recombination is included.}.

We can now successively add the other assumptions of our model:
<<Creating a demographic model in R>>=
dm <- dm.addSpeciationEvent(dm,.1,5)
dm <- dm.addSymmetricMigration(dm,.01,5)
dm <- dm.addMutation(dm,1,20)
dm <- dm.addRecombination(dm,fixed=20)
@
Here, the first parameter is always the demographic model to which we want to add
an assumption/feature. The two following numbers represent the range for the parameter. 
The lower border has to be greater the zero, as we are using a logarithmic transformation
of the parameter space. The parameters are scaled as in the popular simulation program
\verb@ms@ (\cite{hudson_generating_2002}) that we use for simulations:
\begin{itemize}
\item The parameter for the \emph{speciation} event is the split time $\tau$, which
	states how many generations ago the split of the population has occurred.
	As usual in population genetics, its is measured in units of $4N_1$ 
	generations ago, where $N_1$ is the (diploid) effective population size of 
	the first population.
\item The parameter for the (symmetric) \emph{migration} is the scaled migration rate $M$, 
	which is given by $M=4N_1m$, where $m$ is the fraction of individuals of each 
	population which are replaced by immigrants from the other population each
	generation.
\item The \emph{mutation} parameter $\theta$ is $4N_1$ times the neutral mutations
	rate per locus.
\item Finally, the \emph{recombination} parameter $\rho$ is $4N_1$ times
	the probability of recombination between the ends of the locus per generation.
\end{itemize}

\noindent
Finally we can check your model using
<<Checking the model>>=
dm
@

Keep in mind that a `good' model -- which is one that approximates the real demographic
history but is also as simple as possible -- is crucial for obtaining meaningful
estimates in the end. Jaatha will always try to find the parameters that make the
model fit best to your data. If the model does not fit to the data at all,
Jaatha will still return estimates, but they will not be meaningful.

\section{Theoretical Background}
\noindent
It is important to understand the key concepts behind Jaatha before we can apply it. Like many
estimation methods that rely on simulations, Jaatha tries to find the parameters that best fits
\footnote{for Jaatha, the 'best' parameter combination is the one with the highest
composite likelihood} to your data by simulating artificial data for many different parameter
combinations. It uses a learning algorithm to determine how the different parameter
values influence the simulated data and uses that knowledge to find the best parameter combination for 
your data. 

You can imagine Jaatha as a method that runs through the parameter space -- the space
of all possible parameter combinations, in our example a cube with borders from $0.1$ to $5$, 
$0.01$ to $5$ and $1$ to $20$ -- simulating in a small part of the parameter space
around the current position (we call this area a \emph{block}). It then searches the new maximum
of the current blocks and moves to it, builds a new block around it and so on. The search finally 
stops when the likelihood cannot be improved anymore or a maximal number of steps has been reached.

To compare the simulated data to the real one, Jaatha uses \emph{summary statistics} of the data.
As default, it calculates the Joint Site Frequency Spectrum (JSFS) of the data and further summarizes
it by evaluating different sums over the JSFS. Please refer to \cite{naduvilezhath_jaatha:_2011} for a detailed
description.


\section{Importing Your Data}
\noindent
To run Jaatha, you need to calculate the summary statistics of your data. We are currently working on 
a convenient way to do so for popular formats.

For the moment, let us use a simulated data set, for which we know the real parameter:
<<Summary Statistics>>=
pars 	<- c(1,1,10) 
simSumStats <- dm.simSumStats(dm,pars)
simSumStats
@

\section{Running Jaatha}

\noindent
Jaatha is divided into two parts. First we find good starting
positions by simulating very coarsely across the entire parameter space. We call
this part \emph{initial search}. Afterwards a more thorough \emph{refined search}
is performed starting from the best positions of the first step. Before, we need
to set some options like our demographic model and the summary statistics of the 
real data:

<<Initialize>>=
jaatha <- Jaatha.initialize(dm, simSumStats)
@
%startPoints <- Jaatha.initialSearch(j1,nSim=500,nBlocksPerPar=3,multiple=T)
%save(startPoints,file='startpoints.save')

\noindent
For more options refer to \Verb@?Jaatha.initialize@ or the Jaatha manual.

\subsection{The Initial Search}

\noindent
For the initial search, we divide the parameter space into equally-sized blocks by dividing 
each of the $n$ parameters ranges into \verb@nBlocksPerPar@ intervals such that we obtain 
$($\verb@nBlocksPerPar@$)^n$ blocks. Within each block we simulate \verb@nSim@ data sets with 
-- on a logarithmic scale -- uniformly drawn parameter values within each block. To ensure 
a better sampling of the edges, we simulate in addition data sets for all corner points of 
each parameter block.

For these data sets we then fit the GLMs and estimate the parameter combination with the
maximal score. Each of the blocks provides a single best parameter combination.

In R, the initial search is performed with the command

% Don't run a complete jaatha search; would take tooo long
\vspace{0.5em}
\noindent
\verb@> startPoints <- Jaatha.initialSearch(jaatha,nSim=200,nBlocksPerPar=3)@
\vspace{-0.6em}

\noindent
which takes a while, and finally returns a list of start points sorted by score:
<<Initial Search>>=
Jaatha.printStartPoints(jaatha,startPoints)
@
Here, there is a big reduction in the scores after the first five blocks, and a smaller one 
after the first two. This is suggesting that we either use the first two or the first five 
blocks as starting positions for the refined search, depending on how much time we want to
spend. For now, we will just use the first two points.
<<<Pick points>>=
startPoints <- Jaatha.pickBestStartPoints(startPoints,2)
@



\subsection{The Refined Search}

\noindent
Now we can conduct the more thorough refined search described above to improve the
likelihood approximations. 

\noindent
Important: For a typical usage, we recommend setting \verb@nSim=400@, 
\verb@nFinalSim=200@ and \verb@epsilon=2@.

<<seed,include=FALSE,echo=FALSE>>=
set.seed(50)
@

<<RefineSearch>>=
jaatha <- Jaatha.refineSearch(jaatha, startPoints,
                              nSim=50, nFinalSim=50,
			      epsilon=5, halfBlockSize=.05,
			      weight=.9, nMaxStep=200)
@

\noindent
Hence we perform two independent searches, starting in the two \verb@startPoints@ we choose before 
and according to the general options we choose during initialization, which are now stored in the 
\verb@jaatha@ object. In each step, we build a block with \verb@halfBlockSize@ in each direction
(on a logarithmic scale) and perform simulations for \verb@nSim@ random parameter combinations within
this block (plus one for very corner). We use this information to estimate the composite maximum 
likelihood parameters within this block and take this value as new starting position for the next
step. 

The algorithm stops when the score has not changed more than \verb@epsilon@ for five consecutive 
steps or step \verb@nMaxStep@ is reached. To avoid getting stuck in local maxima, 
the \verb@weight@ option decreases the weight of simulations of previous blocks.

Finally the likelihoods for the best ten parameter combinations are approximated using \verb@nFinalSim@
simulations. These are values printed at the end of the search. This matrix can also be accessed via

<<printLT>>=
Jaatha.printLikelihoods(jaatha)
@


\bibliographystyle{plainnat}
\bibliography{jaatha}

\end{document}
